<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_image_classification</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Image-Classification">Image Classification<a class="anchor-link" href="#Image-Classification">&#182;</a></h1><p>In this project, you'll classify images from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a>.  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Run the following cell to download the <a href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">CIFAR-10 dataset for python</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlretrieve</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="k">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">isdir</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="n">cifar10_dataset_folder_path</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-batches-py&#39;</span>

<span class="c1"># Use Floyd&#39;s cifar-10 dataset if present</span>
<span class="n">floyd_cifar10_location</span> <span class="o">=</span> <span class="s1">&#39;/input/cifar-10/python.tar.gz&#39;</span>
<span class="k">if</span> <span class="n">isfile</span><span class="p">(</span><span class="n">floyd_cifar10_location</span><span class="p">):</span>
    <span class="n">tar_gz_path</span> <span class="o">=</span> <span class="n">floyd_cifar10_location</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">tar_gz_path</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-python.tar.gz&#39;</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isfile</span><span class="p">(</span><span class="n">tar_gz_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;CIFAR-10 Dataset&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s1">&#39;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&#39;</span><span class="p">,</span>
            <span class="n">tar_gz_path</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isdir</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">tar_gz_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="n">tests</span><span class="o">.</span><span class="n">test_folder_path</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>All files found!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named <code>data_batch_1</code>, <code>data_batch_2</code>, etc.. Each batch contains the labels and images that are one of the following:</p>
<ul>
<li>airplane</li>
<li>automobile</li>
<li>bird</li>
<li>cat</li>
<li>deer</li>
<li>dog</li>
<li>frog</li>
<li>horse</li>
<li>ship</li>
<li>truck</li>
</ul>
<p>Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the <code>batch_id</code> and <code>sample_id</code>. The <code>batch_id</code> is the id for a batch (1-5). The <code>sample_id</code> is the id for a image and label pair in the batch.</p>
<p>Ask yourself "What are all possible labels?", "What is the range of values for the image data?", "Are the labels in order or random?".  Answers to questions like these will help you preprocess the data and end up with better predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Explore the dataset</span>
<span class="n">batch_id</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sample_id</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">helper</span><span class="o">.</span><span class="n">display_stats</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">sample_id</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Stats of batch 1:
Samples: 10000
Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}
First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]

Example of Image 5:
Image - Min Value: 0 Max Value: 252
Image - Shape: (32, 32, 3)
Label - Label Id: 1 Name: automobile
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=253
height=250
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocess-Functions">Implement Preprocess Functions<a class="anchor-link" href="#Implement-Preprocess-Functions">&#182;</a></h2><h3 id="Normalize">Normalize<a class="anchor-link" href="#Normalize">&#182;</a></h3><p>In the cell below, implement the <code>normalize</code> function to take in image data, <code>x</code>, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as <code>x</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize a list of sample image data in the range of 0 to 1</span>
<span class="sd">    : x: List of image data.  The image shape is (32, 32, 3)</span>
<span class="sd">    : return: Numpy array of normalize data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_normalize</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-hot-encode">One-hot encode<a class="anchor-link" href="#One-hot-encode">&#182;</a></h3><p>Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the <code>one_hot_encode</code> function. The input, <code>x</code>, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to <code>one_hot_encode</code>.  Make sure to save the map of encodings outside the function.</p>
<p>Hint: Don't reinvent the wheel.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">OneHotEncoder</span>

<span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.</span>
<span class="sd">    : x: List of sample Labels</span>
<span class="sd">    : return: Numpy array of one-hot encoded labels</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encoder</span><span class="p">[</span><span class="n">labels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">label</span><span class="p">)]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_one_hot_encode</span><span class="p">(</span><span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Randomize-Data">Randomize Data<a class="anchor-link" href="#Randomize-Data">&#182;</a></h3><p>As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h2><p>Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="c1"># Load the Preprocessed Validation data</span>
<span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_validation.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-network">Build the network<a class="anchor-link" href="#Build-the-network">&#182;</a></h2><p>For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.</p>
<blockquote><p><strong>Note:</strong> If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages to build each layer, except the layers you build in the "Convolutional and Max Pooling Layer" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.</p>
<p>However, if you would like to get the most out of this course, try to solve all the problems <em>without</em> using anything from the TF Layers packages. You <strong>can</strong> still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the <code>conv2d</code> class, <a href="https://www.tensorflow.org/api_docs/python/tf/layers/conv2d">tf.layers.conv2d</a>, you would want to use the TF Neural Network version of <code>conv2d</code>, <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">tf.nn.conv2d</a>.</p>
</blockquote>
<p>Let's begin!</p>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions</p>
<ul>
<li>Implement <code>neural_net_image_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>image_shape</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "x" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_label_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>n_classes</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "y" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_keep_prob_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> for dropout keep probability.</li>
<li>Name the TensorFlow placeholder "keep_prob" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
</ul>
<p>These names will be used at the end of the project to load your saved model.</p>
<p>Note: <code>None</code> for shapes in TensorFlow allow for a dynamic size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">DEFAULT_DTYPE</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span>


<span class="k">def</span> <span class="nf">neural_net_image_input</span><span class="p">(</span><span class="n">image_shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of image input</span>
<span class="sd">    : image_shape: Shape of the images</span>
<span class="sd">    : return: Tensor for image input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">image_shape</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_DTYPE</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">neural_net_label_input</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of label input</span>
<span class="sd">    : n_classes: Number of classes</span>
<span class="sd">    : return: Tensor for label input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_DTYPE</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">neural_net_keep_prob_input</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for keep probability</span>
<span class="sd">    : return: Tensor for keep probability.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_DTYPE</span>
    <span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_image_inputs</span><span class="p">(</span><span class="n">neural_net_image_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_label_inputs</span><span class="p">(</span><span class="n">neural_net_label_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_keep_prob_inputs</span><span class="p">(</span><span class="n">neural_net_keep_prob_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Image Input Tests Passed.
Label Input Tests Passed.
Keep Prob Tests Passed.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convolution-and-Max-Pooling-Layer">Convolution and Max Pooling Layer<a class="anchor-link" href="#Convolution-and-Max-Pooling-Layer">&#182;</a></h3><p>Convolution layers have a lot of success with images. For this code cell, you should implement the function <code>conv2d_maxpool</code> to apply convolution then max pooling:</p>
<ul>
<li>Create the weight and bias using <code>conv_ksize</code>, <code>conv_num_outputs</code> and the shape of <code>x_tensor</code>.</li>
<li>Apply a convolution to <code>x_tensor</code> using weight and <code>conv_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
<li>Add bias</li>
<li>Add a nonlinear activation to the convolution.</li>
<li>Apply Max Pooling using <code>pool_ksize</code> and <code>pool_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
</ul>
<p><strong>Note:</strong> You <strong>can't</strong> use <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> for <strong>this</strong> layer, but you can still use TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/nn">Neural Network</a> package. You may still use the shortcut option for all the <strong>other</strong> layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv2d_maxpool</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">conv_num_outputs</span><span class="p">,</span> <span class="n">conv_ksize</span><span class="p">,</span> <span class="n">conv_strides</span><span class="p">,</span> <span class="n">pool_ksize</span><span class="p">,</span> <span class="n">pool_strides</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply convolution then max pooling to x_tensor</span>
<span class="sd">    :param x_tensor: TensorFlow Tensor</span>
<span class="sd">    :param conv_num_outputs: Number of outputs for the convolutional layer</span>
<span class="sd">    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer</span>
<span class="sd">    :param conv_strides: Stride 2-D Tuple for convolution</span>
<span class="sd">    :param pool_ksize: kernal size 2-D Tuple for pool</span>
<span class="sd">    :param pool_strides: Stride 2-D Tuple for pool</span>
<span class="sd">    : return: A tensor that represents convolution and max pooling of x_tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">xdim</span><span class="p">,</span> <span class="n">ydim</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    
    <span class="c1"># Create the weights and bias using conv_ksize, conv_num_outputs and the shape of x_tensor</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span>
        <span class="n">conv_ksize</span> <span class="o">+</span> <span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">conv_num_outputs</span><span class="p">),</span>
        <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">conv_num_outputs</span><span class="p">,)),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv2d_bias&#39;</span><span class="p">)</span>
    
    <span class="c1"># Apply a convolution to the x_tensor using weight and conv_strides</span>
    <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">conv_strides</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="c1"># data_format == &#39;NHWC&#39;; order == [batch, height, width, channels]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
    
    <span class="c1"># NOTE: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
        <span class="n">x_tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span>
    <span class="p">)</span>
    
    <span class="c1"># Add bias</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    
    <span class="c1"># Add a non-linear activation to the convolution</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># Apply max pooling using pool_ksize and pool_strides</span>
    <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">pool_strides</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
    
    <span class="c1"># NOTE: https://www.tensorflow.org/api_docs/python/tf/nn/max_pool</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">ksize</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">pool_ksize</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_con_pool</span><span class="p">(</span><span class="n">conv2d_maxpool</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Flatten-Layer">Flatten Layer<a class="anchor-link" href="#Flatten-Layer">&#182;</a></h3><p>Implement the <code>flatten</code> function to change the dimension of <code>x_tensor</code> from a 4-D tensor to a 2-D tensor.  The output should be the shape (<em>Batch Size</em>, <em>Flattened Image Size</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flatten x_tensor to (Batch Size, Flattened Image Size)</span>
<span class="sd">    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.</span>
<span class="sd">    : return: A tensor of size (Batch Size, Flattened Image Size).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># NOTE: https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_flatten</span><span class="p">(</span><span class="n">flatten</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Connected-Layer">Fully-Connected Layer<a class="anchor-link" href="#Fully-Connected-Layer">&#182;</a></h3><p>Implement the <code>fully_conn</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fully_conn</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a fully connected layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span>
        <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()</span>
    <span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_fully_conn</span><span class="p">(</span><span class="n">fully_conn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-Layer">Output Layer<a class="anchor-link" href="#Output-Layer">&#182;</a></h3><p>Implement the <code>output</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>
<p><strong>Note:</strong> Activation, softmax, or cross entropy should <strong>not</strong> be applied to this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a output layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span>
        <span class="n">activation_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()</span>
    <span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-Convolutional-Model">Create Convolutional Model<a class="anchor-link" href="#Create-Convolutional-Model">&#182;</a></h3><p>Implement the function <code>conv_net</code> to create a convolutional neural network model. The function takes in a batch of images, <code>x</code>, and outputs logits.  Use the layers you created above to create this model:</p>
<ul>
<li>Apply 1, 2, or 3 Convolution and Max Pool layers</li>
<li>Apply a Flatten Layer</li>
<li>Apply 1, 2, or 3 Fully Connected Layers</li>
<li>Apply an Output Layer</li>
<li>Return the output</li>
<li>Apply <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout">TensorFlow's Dropout</a> to one or more layers in the model using <code>keep_prob</code>. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a convolutional neural network model</span>
<span class="sd">    : x: Placeholder tensor that holds image data.</span>
<span class="sd">    : keep_prob: Placeholder tensor that hold dropout keep probability.</span>
<span class="sd">    : return: Tensor that represents logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Building convnet:&#39;</span><span class="p">)</span>
    <span class="c1"># TODO: Apply 1, 2, or 3 Convolution and Max Pool layers</span>
    <span class="c1">#       Play around with different number of outputs, kernel size and stride</span>
    <span class="c1"># conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;conv_ksize&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="s1">&#39;conv_strides&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;pool_ksize&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;pool_strides&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)}</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="p">{</span><span class="o">**</span><span class="n">defaults</span><span class="p">,</span> <span class="s1">&#39;conv_num_outputs&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)},</span>
        <span class="p">{</span><span class="o">**</span><span class="n">defaults</span><span class="p">,</span> <span class="s1">&#39;conv_num_outputs&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>  <span class="p">},</span>
        <span class="p">{</span><span class="o">**</span><span class="n">defaults</span><span class="p">,</span> <span class="s1">&#39;conv_num_outputs&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="o">/</span><span class="mi">2</span><span class="p">)},</span>
    <span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;+ convolutional max pool layer: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="s1">&#39;conv_num_outputs&#39;</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="s1">&#39;conv_ksize&#39;</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="s1">&#39;conv_strides&#39;</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="s1">&#39;pool_ksize&#39;</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="s1">&#39;pool_strides&#39;</span><span class="p">])</span>
    

    <span class="c1"># TODO: Apply a Flatten Layer</span>
    <span class="c1"># flatten(x_tensor)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;+ flattened layer&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># TODO: Apply 1, 2, or 3 Fully Connected Layers</span>
    <span class="c1">#       Play around with different number of outputs</span>
    <span class="c1"># fully_conn(x_tensor, num_outputs)</span>
    <span class="k">for</span> <span class="n">num_nodes</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span>
        <span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="p">,</span>
        <span class="mi">2</span><span class="o">**</span><span class="mi">8</span>
    <span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;+ fully-connected layer with </span><span class="si">{}</span><span class="s1"> outputs&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;+ dropout layer with </span><span class="si">{}</span><span class="s1"> keep probability&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># TODO: Apply an Output Layer</span>
    <span class="c1">#       Set this to the number of classes</span>
    <span class="c1"># output(x_tensor, num_outputs)</span>
    <span class="n">final_num_outputs</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;+ output layer with </span><span class="si">{}</span><span class="s1"> outputs&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">final_num_outputs</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">final_num_outputs</span><span class="p">)</span>
    
    <span class="c1"># TODO: return output</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">##############################</span>
<span class="c1">## Build the Neural Network ##</span>
<span class="c1">##############################</span>

<span class="c1"># Remove previous weights, bias, inputs, etc..</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="c1"># Inputs</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">neural_net_image_input</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">neural_net_label_input</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">neural_net_keep_prob_input</span><span class="p">()</span>

<span class="c1"># Model</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

<span class="c1"># Name logits Tensor, so that is can be loaded from disk after training</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>

<span class="c1"># Loss and Optimizer</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="c1"># Accuracy</span>
<span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_conv_net</span><span class="p">(</span><span class="n">conv_net</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Building convnet:
+ convolutional max pool layer: {&#39;conv_ksize&#39;: (4, 4), &#39;conv_strides&#39;: (1, 1), &#39;pool_ksize&#39;: (2, 2), &#39;pool_strides&#39;: (2, 2), &#39;conv_num_outputs&#39;: 64}
+ convolutional max pool layer: {&#39;conv_ksize&#39;: (4, 4), &#39;conv_strides&#39;: (1, 1), &#39;pool_ksize&#39;: (2, 2), &#39;pool_strides&#39;: (2, 2), &#39;conv_num_outputs&#39;: 32}
+ convolutional max pool layer: {&#39;conv_ksize&#39;: (4, 4), &#39;conv_strides&#39;: (1, 1), &#39;pool_ksize&#39;: (2, 2), &#39;pool_strides&#39;: (2, 2), &#39;conv_num_outputs&#39;: 16}
+ flattened layer
+ fully-connected layer with 256 outputs
+ fully-connected layer with 256 outputs
+ fully-connected layer with 256 outputs
+ dropout layer with Tensor(&#34;keep_prob:0&#34;, dtype=float32) keep probability
+ output layer with 10 outputs
Building convnet:
+ convolutional max pool layer: {&#39;conv_ksize&#39;: (4, 4), &#39;conv_strides&#39;: (1, 1), &#39;pool_ksize&#39;: (2, 2), &#39;pool_strides&#39;: (2, 2), &#39;conv_num_outputs&#39;: 64}
+ convolutional max pool layer: {&#39;conv_ksize&#39;: (4, 4), &#39;conv_strides&#39;: (1, 1), &#39;pool_ksize&#39;: (2, 2), &#39;pool_strides&#39;: (2, 2), &#39;conv_num_outputs&#39;: 32}
+ convolutional max pool layer: {&#39;conv_ksize&#39;: (4, 4), &#39;conv_strides&#39;: (1, 1), &#39;pool_ksize&#39;: (2, 2), &#39;pool_strides&#39;: (2, 2), &#39;conv_num_outputs&#39;: 16}
+ flattened layer
+ fully-connected layer with 256 outputs
+ fully-connected layer with 256 outputs
+ fully-connected layer with 256 outputs
+ dropout layer with Tensor(&#34;Placeholder_1:0&#34;, dtype=float32) keep probability
+ output layer with 10 outputs
Neural Network Built!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-the-Neural-Network">Train the Neural Network<a class="anchor-link" href="#Train-the-Neural-Network">&#182;</a></h2><h3 id="Single-Optimization">Single Optimization<a class="anchor-link" href="#Single-Optimization">&#182;</a></h3><p>Implement the function <code>train_neural_network</code> to do a single optimization.  The optimization should use <code>optimizer</code> to optimize in <code>session</code> with a <code>feed_dict</code> of the following:</p>
<ul>
<li><code>x</code> for image input</li>
<li><code>y</code> for labels</li>
<li><code>keep_prob</code> for keep probability for dropout</li>
</ul>
<p>This function will be called for each batch, so <code>tf.global_variables_initializer()</code> has already been called.</p>
<p>Note: Nothing needs to be returned. This function is only optimizing the neural network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_neural_network</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Optimize the session on a batch of images and labels</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : optimizer: TensorFlow optimizer function</span>
<span class="sd">    : keep_probability: keep probability</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span>
    <span class="p">})</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_train_nn</span><span class="p">(</span><span class="n">train_neural_network</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Show-Stats">Show Stats<a class="anchor-link" href="#Show-Stats">&#182;</a></h3><p>Implement the function <code>print_stats</code> to print loss and validation accuracy.  Use the global variables <code>valid_features</code> and <code>valid_labels</code> to calculate validation accuracy.  Use a keep probability of <code>1.0</code> to calculate the loss and validation accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print information about loss and validation accuracy</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    : cost: TensorFlow cost function</span>
<span class="sd">    : accuracy: TensorFlow accuracy function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">global</span> <span class="n">valid_features</span>
    <span class="k">global</span> <span class="n">valid_labels</span>
    
    <span class="n">loss_train</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span>     <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span>  <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">,</span>  <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="n">loss_valid</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span>     <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">valid_features</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">valid_labels</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="n">acc_valid</span>  <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">valid_features</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">valid_labels</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training Loss: </span><span class="si">{:.4f}</span><span class="s1">, Validation Loss: </span><span class="si">{:.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss_train</span><span class="p">,</span> <span class="n">loss_valid</span><span class="p">,</span> <span class="n">acc_valid</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of iterations until the network stops learning or start overfitting</li>
<li>Set <code>batch_size</code> to the highest number that your machine has memory for.  Most people set them to common sizes of memory:<ul>
<li>64</li>
<li>128</li>
<li>256</li>
<li>...</li>
</ul>
</li>
<li>Set <code>keep_probability</code> to the probability of keeping a node using dropout</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: Tune Parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">8</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-on-a-Single-CIFAR-10-Batch">Train on a Single CIFAR-10 Batch<a class="anchor-link" href="#Train-on-a-Single-CIFAR-10-Batch">&#182;</a></h3><p>Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking the Training on a Single Batch...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking the Training on a Single Batch...
Epoch  1, CIFAR-10 Batch 1:  Training Loss: 2.1478, Validation Loss: 2.0638, Validation Accuracy: 0.2422
Epoch  2, CIFAR-10 Batch 1:  Training Loss: 1.8803, Validation Loss: 1.7748, Validation Accuracy: 0.3568
Epoch  3, CIFAR-10 Batch 1:  Training Loss: 1.5475, Validation Loss: 1.6381, Validation Accuracy: 0.4096
Epoch  4, CIFAR-10 Batch 1:  Training Loss: 1.4307, Validation Loss: 1.5723, Validation Accuracy: 0.4308
Epoch  5, CIFAR-10 Batch 1:  Training Loss: 1.3725, Validation Loss: 1.7381, Validation Accuracy: 0.3898
Epoch  6, CIFAR-10 Batch 1:  Training Loss: 1.1989, Validation Loss: 1.5516, Validation Accuracy: 0.4432
Epoch  7, CIFAR-10 Batch 1:  Training Loss: 0.9571, Validation Loss: 1.4551, Validation Accuracy: 0.4722
Epoch  8, CIFAR-10 Batch 1:  Training Loss: 0.8257, Validation Loss: 1.4848, Validation Accuracy: 0.4692
Epoch  9, CIFAR-10 Batch 1:  Training Loss: 0.6862, Validation Loss: 1.4535, Validation Accuracy: 0.4888
Epoch 10, CIFAR-10 Batch 1:  Training Loss: 0.6147, Validation Loss: 1.4281, Validation Accuracy: 0.4936
Epoch 11, CIFAR-10 Batch 1:  Training Loss: 0.5336, Validation Loss: 1.4546, Validation Accuracy: 0.4826
Epoch 12, CIFAR-10 Batch 1:  Training Loss: 0.6499, Validation Loss: 1.7545, Validation Accuracy: 0.4324
Epoch 13, CIFAR-10 Batch 1:  Training Loss: 0.5053, Validation Loss: 1.4011, Validation Accuracy: 0.4982
Epoch 14, CIFAR-10 Batch 1:  Training Loss: 0.4150, Validation Loss: 1.5284, Validation Accuracy: 0.4724
Epoch 15, CIFAR-10 Batch 1:  Training Loss: 0.3841, Validation Loss: 1.5465, Validation Accuracy: 0.4894
Epoch 16, CIFAR-10 Batch 1:  Training Loss: 0.2856, Validation Loss: 1.5556, Validation Accuracy: 0.5110
Epoch 17, CIFAR-10 Batch 1:  Training Loss: 0.2372, Validation Loss: 1.6619, Validation Accuracy: 0.5026
Epoch 18, CIFAR-10 Batch 1:  Training Loss: 0.2300, Validation Loss: 1.6039, Validation Accuracy: 0.5090
Epoch 19, CIFAR-10 Batch 1:  Training Loss: 0.2367, Validation Loss: 1.5068, Validation Accuracy: 0.5266
Epoch 20, CIFAR-10 Batch 1:  Training Loss: 0.2577, Validation Loss: 1.4819, Validation Accuracy: 0.5234
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(Extra)-Visualize-Graph">(Extra) Visualize Graph<a class="anchor-link" href="#(Extra)-Visualize-Graph">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Reference: https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">clear_output</span><span class="p">,</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>

<span class="k">def</span> <span class="nf">strip_consts</span><span class="p">(</span><span class="n">graph_def</span><span class="p">,</span> <span class="n">max_const_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Strip large constant values from graph_def.&quot;&quot;&quot;</span>
    <span class="n">strip_def</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">GraphDef</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">n0</span> <span class="ow">in</span> <span class="n">graph_def</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">strip_def</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">add</span><span class="p">()</span> 
        <span class="n">n</span><span class="o">.</span><span class="n">MergeFrom</span><span class="p">(</span><span class="n">n0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s1">&#39;Const&#39;</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tensor</span>
            <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">tensor_content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">max_const_size</span><span class="p">:</span>
                <span class="n">tensor</span><span class="o">.</span><span class="n">tensor_content</span> <span class="o">=</span> <span class="s2">&quot;&lt;stripped </span><span class="si">%d</span><span class="s2"> bytes&gt;&quot;</span><span class="o">%</span><span class="k">size</span>
    <span class="k">return</span> <span class="n">strip_def</span>

<span class="k">def</span> <span class="nf">show_graph</span><span class="p">(</span><span class="n">graph_def</span><span class="p">,</span> <span class="n">max_const_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Visualize TensorFlow graph.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">graph_def</span><span class="p">,</span> <span class="s1">&#39;as_graph_def&#39;</span><span class="p">):</span>
        <span class="n">graph_def</span> <span class="o">=</span> <span class="n">graph_def</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">()</span>
    <span class="n">strip_def</span> <span class="o">=</span> <span class="n">strip_consts</span><span class="p">(</span><span class="n">graph_def</span><span class="p">,</span> <span class="n">max_const_size</span><span class="o">=</span><span class="n">max_const_size</span><span class="p">)</span>
    <span class="n">code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        &lt;script&gt;</span>
<span class="s2">          function load() {{</span>
<span class="s2">            document.getElementById(&quot;</span><span class="si">{id}</span><span class="s2">&quot;).pbtxt = </span><span class="si">{data}</span><span class="s2">;</span>
<span class="s2">          }}</span>
<span class="s2">        &lt;/script&gt;</span>
<span class="s2">        &lt;link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()&gt;</span>
<span class="s2">        &lt;div style=&quot;height:600px&quot;&gt;</span>
<span class="s2">          &lt;tf-graph-basic id=&quot;</span><span class="si">{id}</span><span class="s2">&quot;&gt;&lt;/tf-graph-basic&gt;</span>
<span class="s2">        &lt;/div&gt;</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">strip_def</span><span class="p">)),</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;graph&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()))</span>

    <span class="n">iframe</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        &lt;iframe seamless style=&quot;width:1200px;height:620px;border:0&quot; srcdoc=&quot;</span><span class="si">{}</span><span class="s2">&quot;&gt;&lt;/iframe&gt;</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">code</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;&quot;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;quot;&#39;</span><span class="p">))</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">iframe</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_graph</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>


<div class="output_html rendered_html output_subarea ">

        <iframe seamless style="width:1200px;height:620px;border:0" srcdoc="
        <script>
          function load() {
            document.getElementById(&quot;graph0.6255653082276177&quot;).pbtxt = 'node {\n  name: &quot;x&quot;\n  op: &quot;Placeholder&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 3\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y&quot;\n  op: &quot;Placeholder&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;keep_prob&quot;\n  op: &quot;Placeholder&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        unknown_rank: true\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;truncated_normal/TruncatedNormal&quot;\n  input: &quot;truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;truncated_normal/mul&quot;\n  input: &quot;truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Variable&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 3\n        }\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable&quot;\n  input: &quot;truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 64\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias&quot;\n  input: &quot;zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Conv2D&quot;\n  op: &quot;Conv2D&quot;\n  input: &quot;x&quot;\n  input: &quot;Variable/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;Conv2D&quot;\n  input: &quot;conv2d_bias/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;MaxPool&quot;\n  op: &quot;MaxPool&quot;\n  input: &quot;Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_1/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000@\\000\\000\\000 \\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_1/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_1/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_1/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;truncated_normal_1/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_1/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;truncated_normal_1/TruncatedNormal&quot;\n  input: &quot;truncated_normal_1/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_1&quot;\n  op: &quot;Add&quot;\n  input: &quot;truncated_normal_1/mul&quot;\n  input: &quot;truncated_normal_1/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 64\n        }\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_1&quot;\n  input: &quot;truncated_normal_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;zeros_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 32\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_1&quot;\n  input: &quot;zeros_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Conv2D_1&quot;\n  op: &quot;Conv2D&quot;\n  input: &quot;MaxPool&quot;\n  input: &quot;Variable_1/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;BiasAdd_1&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;Conv2D_1&quot;\n  input: &quot;conv2d_bias_1/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Relu_1&quot;\n  op: &quot;Relu&quot;\n  input: &quot;BiasAdd_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;MaxPool_1&quot;\n  op: &quot;MaxPool&quot;\n  input: &quot;Relu_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_2/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000 \\000\\000\\000\\020\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_2/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_2/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_2/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;truncated_normal_2/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_2/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;truncated_normal_2/TruncatedNormal&quot;\n  input: &quot;truncated_normal_2/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_2&quot;\n  op: &quot;Add&quot;\n  input: &quot;truncated_normal_2/mul&quot;\n  input: &quot;truncated_normal_2/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_2&quot;\n  input: &quot;truncated_normal_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;zeros_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 16\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_2&quot;\n  input: &quot;zeros_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Conv2D_2&quot;\n  op: &quot;Conv2D&quot;\n  input: &quot;MaxPool_1&quot;\n  input: &quot;Variable_2/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;BiasAdd_2&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;Conv2D_2&quot;\n  input: &quot;conv2d_bias_2/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Relu_2&quot;\n  op: &quot;Relu&quot;\n  input: &quot;BiasAdd_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;MaxPool_2&quot;\n  op: &quot;MaxPool&quot;\n  input: &quot;Relu_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;MaxPool_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Slice/begin&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Slice/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Slice&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Flatten/Shape&quot;\n  input: &quot;Flatten/Slice/begin&quot;\n  input: &quot;Flatten/Slice/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Slice_1/begin&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Slice_1/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 3\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Slice_1&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Flatten/Shape&quot;\n  input: &quot;Flatten/Slice_1/begin&quot;\n  input: &quot;Flatten/Slice_1/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Prod&quot;\n  op: &quot;Prod&quot;\n  input: &quot;Flatten/Slice_1&quot;\n  input: &quot;Flatten/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/ExpandDims/dim&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/ExpandDims&quot;\n  op: &quot;ExpandDims&quot;\n  input: &quot;Flatten/Prod&quot;\n  input: &quot;Flatten/ExpandDims/dim&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tdim&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/concat/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/concat&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;Flatten/Slice&quot;\n  input: &quot;Flatten/ExpandDims&quot;\n  input: &quot;Flatten/concat/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;MaxPool_2&quot;\n  input: &quot;Flatten/concat&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\000\\001\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected/weights&quot;\n  input: &quot;fully_connected/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected/biases&quot;\n  input: &quot;fully_connected/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;Flatten/Reshape&quot;\n  input: &quot;fully_connected/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected/MatMul&quot;\n  input: &quot;fully_connected/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;fully_connected/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\000\\001\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_1/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_1/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_1/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_1/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_1/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_1/weights&quot;\n  input: &quot;fully_connected_1/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_1/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_1/biases&quot;\n  input: &quot;fully_connected_1/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_1/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;fully_connected/Relu&quot;\n  input: &quot;fully_connected_1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_1/MatMul&quot;\n  input: &quot;fully_connected_1/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;fully_connected_1/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\000\\001\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_2/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_2/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_2/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_2/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_2/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_2/weights&quot;\n  input: &quot;fully_connected_2/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_2/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_2/biases&quot;\n  input: &quot;fully_connected_2/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_2/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;fully_connected_1/Relu&quot;\n  input: &quot;fully_connected_2/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_2/MatMul&quot;\n  input: &quot;fully_connected_2/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;fully_connected_2/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;fully_connected_2/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;dropout/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;dropout/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;dropout/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;dropout/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;dropout/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;dropout/random_uniform/max&quot;\n  input: &quot;dropout/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;dropout/random_uniform/RandomUniform&quot;\n  input: &quot;dropout/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;dropout/random_uniform/mul&quot;\n  input: &quot;dropout/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;keep_prob&quot;\n  input: &quot;dropout/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/Floor&quot;\n  op: &quot;Floor&quot;\n  input: &quot;dropout/add&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/div&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;fully_connected_2/Relu&quot;\n  input: &quot;keep_prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;dropout/div&quot;\n  input: &quot;dropout/Floor&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\n\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_3/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_3/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_3/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_3/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_3/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_3/weights&quot;\n  input: &quot;fully_connected_3/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 10\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_3/biases&quot;\n  input: &quot;fully_connected_3/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;dropout/mul&quot;\n  input: &quot;fully_connected_3/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_3/MatMul&quot;\n  input: &quot;fully_connected_3/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;logits&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Rank&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;logits&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Rank_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;logits&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Sub/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;Rank_1&quot;\n  input: &quot;Sub/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Slice/begin&quot;\n  op: &quot;Pack&quot;\n  input: &quot;Sub&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;Slice/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Slice&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Shape_1&quot;\n  input: &quot;Slice/begin&quot;\n  input: &quot;Slice/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;concat/values_0&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;concat/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;concat&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;concat/values_0&quot;\n  input: &quot;Slice&quot;\n  input: &quot;concat/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;logits&quot;\n  input: &quot;concat&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Rank_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Shape_2&quot;\n  op: &quot;Shape&quot;\n  input: &quot;y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Sub_1/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Sub_1&quot;\n  op: &quot;Sub&quot;\n  input: &quot;Rank_2&quot;\n  input: &quot;Sub_1/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Slice_1/begin&quot;\n  op: &quot;Pack&quot;\n  input: &quot;Sub_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;Slice_1/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Slice_1&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Shape_2&quot;\n  input: &quot;Slice_1/begin&quot;\n  input: &quot;Slice_1/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;concat_1/values_0&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;concat_1/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;concat_1&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;concat_1/values_0&quot;\n  input: &quot;Slice_1&quot;\n  input: &quot;concat_1/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;y&quot;\n  input: &quot;concat_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;SoftmaxCrossEntropyWithLogits&quot;\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\n  input: &quot;Reshape&quot;\n  input: &quot;Reshape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Sub_2/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Sub_2&quot;\n  op: &quot;Sub&quot;\n  input: &quot;Rank&quot;\n  input: &quot;Sub_2/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Slice_2/begin&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Slice_2/size&quot;\n  op: &quot;Pack&quot;\n  input: &quot;Sub_2&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;Slice_2&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Shape&quot;\n  input: &quot;Slice_2/begin&quot;\n  input: &quot;Slice_2/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Reshape_2&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\n  input: &quot;Slice_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Mean&quot;\n  op: &quot;Mean&quot;\n  input: &quot;Reshape_2&quot;\n  input: &quot;Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;gradients/Shape&quot;\n  input: &quot;gradients/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/Fill&quot;\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;Reshape_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/Mean_grad/Reshape&quot;\n  input: &quot;gradients/Mean_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;Reshape_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Prod&quot;\n  op: &quot;Prod&quot;\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\n  input: &quot;gradients/Mean_grad/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Const_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\n  op: &quot;Prod&quot;\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\n  input: &quot;gradients/Mean_grad/Const_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Maximum&quot;\n  op: &quot;Maximum&quot;\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/floordiv&quot;\n  op: &quot;FloorDiv&quot;\n  input: &quot;gradients/Mean_grad/Prod&quot;\n  input: &quot;gradients/Mean_grad/Maximum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/Cast&quot;\n  op: &quot;Cast&quot;\n  input: &quot;gradients/Mean_grad/floordiv&quot;\n  attr {\n    key: &quot;DstT&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;SrcT&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Mean_grad/truediv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/Mean_grad/Tile&quot;\n  input: &quot;gradients/Mean_grad/Cast&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Reshape_2_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;SoftmaxCrossEntropyWithLogits&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Reshape_2_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/Mean_grad/truediv&quot;\n  input: &quot;gradients/Reshape_2_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/zeros_like&quot;\n  op: &quot;ZerosLike&quot;\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\n  op: &quot;ExpandDims&quot;\n  input: &quot;gradients/Reshape_2_grad/Reshape&quot;\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tdim&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\n  input: &quot;SoftmaxCrossEntropyWithLogits:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Reshape_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;logits&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\n  input: &quot;gradients/Reshape_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Reshape_grad/Reshape&quot;\n  input: &quot;^gradients/fully_connected_3/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected_3/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\n  input: &quot;^gradients/fully_connected_3/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Reshape_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_3/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/fully_connected_3/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_3/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/fully_connected_3/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected_3/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;dropout/mul&quot;\n  input: &quot;gradients/fully_connected_3/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected_3/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected_3/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected_3/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_3/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected_3/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_3/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_3/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_3/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/fully_connected_3/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_3/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;dropout/div&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;dropout/Floor&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/dropout/mul_grad/Shape&quot;\n  input: &quot;gradients/dropout/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/fully_connected_3/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;dropout/Floor&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/dropout/mul_grad/mul&quot;\n  input: &quot;gradients/dropout/mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/dropout/mul_grad/Sum&quot;\n  input: &quot;gradients/dropout/mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;dropout/div&quot;\n  input: &quot;gradients/fully_connected_3/MatMul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/dropout/mul_grad/mul_1&quot;\n  input: &quot;gradients/dropout/mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/dropout/mul_grad/Sum_1&quot;\n  input: &quot;gradients/dropout/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/dropout/mul_grad/Reshape&quot;\n  input: &quot;^gradients/dropout/mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/dropout/mul_grad/Reshape&quot;\n  input: &quot;^gradients/dropout/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/dropout/mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/dropout/mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/dropout/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/dropout/mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;fully_connected_2/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;keep_prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/dropout/div_grad/Shape&quot;\n  input: &quot;gradients/dropout/div_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/dropout/mul_grad/tuple/control_dependency&quot;\n  input: &quot;keep_prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/dropout/div_grad/RealDiv&quot;\n  input: &quot;gradients/dropout/div_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/dropout/div_grad/Sum&quot;\n  input: &quot;gradients/dropout/div_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;fully_connected_2/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/dropout/div_grad/Neg&quot;\n  input: &quot;keep_prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/dropout/div_grad/RealDiv_1&quot;\n  input: &quot;keep_prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/dropout/mul_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/dropout/div_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/dropout/div_grad/mul&quot;\n  input: &quot;gradients/dropout/div_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/dropout/div_grad/Sum_1&quot;\n  input: &quot;gradients/dropout/div_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/dropout/div_grad/Reshape&quot;\n  input: &quot;^gradients/dropout/div_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/dropout/div_grad/Reshape&quot;\n  input: &quot;^gradients/dropout/div_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/dropout/div_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/dropout/div_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/dropout/div_grad/Reshape_1&quot;\n  input: &quot;^gradients/dropout/div_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/dropout/div_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/dropout/div_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected_2/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/fully_connected_2/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected_2/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/fully_connected_2/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected_2/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_2/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/fully_connected_2/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_2/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_2/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/fully_connected_2/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_2/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/fully_connected_2/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected_2/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;fully_connected_1/Relu&quot;\n  input: &quot;gradients/fully_connected_2/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected_2/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected_2/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected_2/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_2/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected_2/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_2/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_2/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_2/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/fully_connected_2/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_2/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/fully_connected_2/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected_1/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/fully_connected_1/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected_1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/fully_connected_1/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected_1/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/fully_connected_1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_1/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_1/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/fully_connected_1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/fully_connected_1/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected_1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;fully_connected/Relu&quot;\n  input: &quot;gradients/fully_connected_1/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected_1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected_1/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected_1/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected_1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_1/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected_1/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected_1/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/fully_connected_1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected_1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/fully_connected_1/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/fully_connected/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/fully_connected/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/fully_connected/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/fully_connected/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/fully_connected/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;fully_connected/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;Flatten/Reshape&quot;\n  input: &quot;gradients/fully_connected/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/fully_connected/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/fully_connected/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/fully_connected/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/fully_connected/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/fully_connected/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/fully_connected/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/fully_connected/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Flatten/Reshape_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;MaxPool_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Flatten/Reshape_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/fully_connected/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/Flatten/Reshape_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/MaxPool_2_grad/MaxPoolGrad&quot;\n  op: &quot;MaxPoolGrad&quot;\n  input: &quot;Relu_2&quot;\n  input: &quot;MaxPool_2&quot;\n  input: &quot;gradients/Flatten/Reshape_grad/Reshape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Relu_2_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/MaxPool_2_grad/MaxPoolGrad&quot;\n  input: &quot;Relu_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_2_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/Relu_2_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_2_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Relu_2_grad/ReluGrad&quot;\n  input: &quot;^gradients/BiasAdd_2_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/BiasAdd_2_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Relu_2_grad/ReluGrad&quot;\n  input: &quot;^gradients/BiasAdd_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Relu_2_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_2_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/BiasAdd_2_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/BiasAdd_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/BiasAdd_2_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;MaxPool_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/Conv2DBackpropInput&quot;\n  op: &quot;Conv2DBackpropInput&quot;\n  input: &quot;gradients/Conv2D_2_grad/Shape&quot;\n  input: &quot;Variable_2/read&quot;\n  input: &quot;gradients/BiasAdd_2_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000 \\000\\000\\000\\020\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/Conv2DBackpropFilter&quot;\n  op: &quot;Conv2DBackpropFilter&quot;\n  input: &quot;MaxPool_1&quot;\n  input: &quot;gradients/Conv2D_2_grad/Shape_1&quot;\n  input: &quot;gradients/BiasAdd_2_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Conv2D_2_grad/Conv2DBackpropInput&quot;\n  input: &quot;^gradients/Conv2D_2_grad/Conv2DBackpropFilter&quot;\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Conv2D_2_grad/Conv2DBackpropInput&quot;\n  input: &quot;^gradients/Conv2D_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Conv2D_2_grad/Conv2DBackpropInput&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_2_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Conv2D_2_grad/Conv2DBackpropFilter&quot;\n  input: &quot;^gradients/Conv2D_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Conv2D_2_grad/Conv2DBackpropFilter&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/MaxPool_1_grad/MaxPoolGrad&quot;\n  op: &quot;MaxPoolGrad&quot;\n  input: &quot;Relu_1&quot;\n  input: &quot;MaxPool_1&quot;\n  input: &quot;gradients/Conv2D_2_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Relu_1_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/MaxPool_1_grad/MaxPoolGrad&quot;\n  input: &quot;Relu_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_1_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/Relu_1_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Relu_1_grad/ReluGrad&quot;\n  input: &quot;^gradients/BiasAdd_1_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/BiasAdd_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Relu_1_grad/ReluGrad&quot;\n  input: &quot;^gradients/BiasAdd_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Relu_1_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/BiasAdd_1_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/BiasAdd_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/BiasAdd_1_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;MaxPool&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/Conv2DBackpropInput&quot;\n  op: &quot;Conv2DBackpropInput&quot;\n  input: &quot;gradients/Conv2D_1_grad/Shape&quot;\n  input: &quot;Variable_1/read&quot;\n  input: &quot;gradients/BiasAdd_1_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000@\\000\\000\\000 \\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/Conv2DBackpropFilter&quot;\n  op: &quot;Conv2DBackpropFilter&quot;\n  input: &quot;MaxPool&quot;\n  input: &quot;gradients/Conv2D_1_grad/Shape_1&quot;\n  input: &quot;gradients/BiasAdd_1_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Conv2D_1_grad/Conv2DBackpropInput&quot;\n  input: &quot;^gradients/Conv2D_1_grad/Conv2DBackpropFilter&quot;\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Conv2D_1_grad/Conv2DBackpropInput&quot;\n  input: &quot;^gradients/Conv2D_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Conv2D_1_grad/Conv2DBackpropInput&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Conv2D_1_grad/Conv2DBackpropFilter&quot;\n  input: &quot;^gradients/Conv2D_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Conv2D_1_grad/Conv2DBackpropFilter&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/MaxPool_grad/MaxPoolGrad&quot;\n  op: &quot;MaxPoolGrad&quot;\n  input: &quot;Relu&quot;\n  input: &quot;MaxPool&quot;\n  input: &quot;gradients/Conv2D_1_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/MaxPool_grad/MaxPoolGrad&quot;\n  input: &quot;Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\n  op: &quot;Conv2DBackpropInput&quot;\n  input: &quot;gradients/Conv2D_grad/Shape&quot;\n  input: &quot;Variable/read&quot;\n  input: &quot;gradients/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\n  op: &quot;Conv2DBackpropFilter&quot;\n  input: &quot;x&quot;\n  input: &quot;gradients/Conv2D_grad/Shape_1&quot;\n  input: &quot;gradients/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropInput&quot;\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropInput&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power/initial_value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.8999999761581421\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta1_power&quot;\n  input: &quot;beta1_power/initial_value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;beta1_power&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power/initial_value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.9990000128746033\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta2_power&quot;\n  input: &quot;beta2_power/initial_value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;beta2_power&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n          dim {\n            size: 3\n          }\n          dim {\n            size: 64\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 3\n        }\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable/Adam&quot;\n  input: &quot;Variable/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n          dim {\n            size: 3\n          }\n          dim {\n            size: 64\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 3\n        }\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable/Adam_1&quot;\n  input: &quot;Variable/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 64\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias/Adam&quot;\n  input: &quot;conv2d_bias/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 64\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias/Adam_1&quot;\n  input: &quot;conv2d_bias/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n          dim {\n            size: 64\n          }\n          dim {\n            size: 32\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 64\n        }\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_1/Adam&quot;\n  input: &quot;Variable_1/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_1/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n          dim {\n            size: 64\n          }\n          dim {\n            size: 32\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 64\n        }\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_1/Adam_1&quot;\n  input: &quot;Variable_1/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_1/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_1/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 32\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_1/Adam&quot;\n  input: &quot;conv2d_bias_1/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_1/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 32\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_1/Adam_1&quot;\n  input: &quot;conv2d_bias_1/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_1/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_1/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n          dim {\n            size: 32\n          }\n          dim {\n            size: 16\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_2/Adam&quot;\n  input: &quot;Variable_2/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_2/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n          dim {\n            size: 32\n          }\n          dim {\n            size: 16\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_2/Adam_1&quot;\n  input: &quot;Variable_2/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_2/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_2/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 16\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_2/Adam&quot;\n  input: &quot;conv2d_bias_2/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_2/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 16\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_2/Adam_1&quot;\n  input: &quot;conv2d_bias_2/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_2/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_2/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected/weights/Adam&quot;\n  input: &quot;fully_connected/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected/weights/Adam_1&quot;\n  input: &quot;fully_connected/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected/biases/Adam&quot;\n  input: &quot;fully_connected/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected/biases/Adam_1&quot;\n  input: &quot;fully_connected/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_1/weights/Adam&quot;\n  input: &quot;fully_connected_1/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_1/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_1/weights/Adam_1&quot;\n  input: &quot;fully_connected_1/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_1/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_1/biases/Adam&quot;\n  input: &quot;fully_connected_1/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_1/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_1/biases/Adam_1&quot;\n  input: &quot;fully_connected_1/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_1/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_1/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_2/weights/Adam&quot;\n  input: &quot;fully_connected_2/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_2/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_2/weights/Adam_1&quot;\n  input: &quot;fully_connected_2/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_2/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_2/biases/Adam&quot;\n  input: &quot;fully_connected_2/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_2/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_2/biases/Adam_1&quot;\n  input: &quot;fully_connected_2/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_2/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_2/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 10\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_3/weights/Adam&quot;\n  input: &quot;fully_connected_3/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n          dim {\n            size: 10\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_3/weights/Adam_1&quot;\n  input: &quot;fully_connected_3/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 10\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_3/biases/Adam&quot;\n  input: &quot;fully_connected_3/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 10\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_3/biases/Adam_1&quot;\n  input: &quot;fully_connected_3/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_3/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_3/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/learning_rate&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0010000000474974513\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/beta1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.8999999761581421\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/beta2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.9990000128746033\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/epsilon&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 9.99999993922529e-09\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_Variable/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;Variable&quot;\n  input: &quot;Variable/Adam&quot;\n  input: &quot;Variable/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_conv2d_bias/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;conv2d_bias&quot;\n  input: &quot;conv2d_bias/Adam&quot;\n  input: &quot;conv2d_bias/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_Variable_1/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;Variable_1&quot;\n  input: &quot;Variable_1/Adam&quot;\n  input: &quot;Variable_1/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/Conv2D_1_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_conv2d_bias_1/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;conv2d_bias_1&quot;\n  input: &quot;conv2d_bias_1/Adam&quot;\n  input: &quot;conv2d_bias_1/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/BiasAdd_1_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_1&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_Variable_2/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;Variable_2&quot;\n  input: &quot;Variable_2/Adam&quot;\n  input: &quot;Variable_2/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/Conv2D_2_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_conv2d_bias_2/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;conv2d_bias_2&quot;\n  input: &quot;conv2d_bias_2/Adam&quot;\n  input: &quot;conv2d_bias_2/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/BiasAdd_2_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_2&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected/weights&quot;\n  input: &quot;fully_connected/weights/Adam&quot;\n  input: &quot;fully_connected/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected/biases&quot;\n  input: &quot;fully_connected/biases/Adam&quot;\n  input: &quot;fully_connected/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected_1/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected_1/weights&quot;\n  input: &quot;fully_connected_1/weights/Adam&quot;\n  input: &quot;fully_connected_1/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected_1/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected_1/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected_1/biases&quot;\n  input: &quot;fully_connected_1/biases/Adam&quot;\n  input: &quot;fully_connected_1/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected_2/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected_2/weights&quot;\n  input: &quot;fully_connected_2/weights/Adam&quot;\n  input: &quot;fully_connected_2/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected_2/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected_2/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected_2/biases&quot;\n  input: &quot;fully_connected_2/biases/Adam&quot;\n  input: &quot;fully_connected_2/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected_2/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_2/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected_3/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected_3/weights&quot;\n  input: &quot;fully_connected_3/weights/Adam&quot;\n  input: &quot;fully_connected_3/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected_3/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_fully_connected_3/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;fully_connected_3/biases&quot;\n  input: &quot;fully_connected_3/biases/Adam&quot;\n  input: &quot;fully_connected_3/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/fully_connected_3/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_3/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;^Adam/update_Variable/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias/ApplyAdam&quot;\n  input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias_1/ApplyAdam&quot;\n  input: &quot;^Adam/update_Variable_2/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias_2/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_2/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_2/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_3/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_3/biases/ApplyAdam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta1_power&quot;\n  input: &quot;Adam/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Adam/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;^Adam/update_Variable/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias/ApplyAdam&quot;\n  input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias_1/ApplyAdam&quot;\n  input: &quot;^Adam/update_Variable_2/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias_2/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_2/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_2/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_3/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_3/biases/ApplyAdam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/Assign_1&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta2_power&quot;\n  input: &quot;Adam/mul_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Adam&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^Adam/update_Variable/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias/ApplyAdam&quot;\n  input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias_1/ApplyAdam&quot;\n  input: &quot;^Adam/update_Variable_2/ApplyAdam&quot;\n  input: &quot;^Adam/update_conv2d_bias_2/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_2/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_2/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_3/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_fully_connected_3/biases/ApplyAdam&quot;\n  input: &quot;^Adam/Assign&quot;\n  input: &quot;^Adam/Assign_1&quot;\n}\nnode {\n  name: &quot;ArgMax/dimension&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;ArgMax&quot;\n  op: &quot;ArgMax&quot;\n  input: &quot;logits&quot;\n  input: &quot;ArgMax/dimension&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;ArgMax_1/dimension&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;ArgMax_1&quot;\n  op: &quot;ArgMax&quot;\n  input: &quot;y&quot;\n  input: &quot;ArgMax_1/dimension&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Equal&quot;\n  op: &quot;Equal&quot;\n  input: &quot;ArgMax&quot;\n  input: &quot;ArgMax_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT64\n    }\n  }\n}\nnode {\n  name: &quot;Cast_1&quot;\n  op: &quot;Cast&quot;\n  input: &quot;Equal&quot;\n  attr {\n    key: &quot;DstT&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;SrcT&quot;\n    value {\n      type: DT_BOOL\n    }\n  }\n}\nnode {\n  name: &quot;Const_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;accuracy&quot;\n  op: &quot;Mean&quot;\n  input: &quot;Cast_1&quot;\n  input: &quot;Const_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Placeholder&quot;\n  op: &quot;Placeholder&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 3\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Placeholder_1&quot;\n  op: &quot;Placeholder&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        unknown_rank: true\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_3/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_3/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_3/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_3/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;truncated_normal_3/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_3/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;truncated_normal_3/TruncatedNormal&quot;\n  input: &quot;truncated_normal_3/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_3&quot;\n  op: &quot;Add&quot;\n  input: &quot;truncated_normal_3/mul&quot;\n  input: &quot;truncated_normal_3/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Variable_3&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 3\n        }\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_3/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_3&quot;\n  input: &quot;truncated_normal_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_3&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_3/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_3&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;zeros_3&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 64\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_3&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 64\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_3/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_3&quot;\n  input: &quot;zeros_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_3&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_3/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_3&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Conv2D_3&quot;\n  op: &quot;Conv2D&quot;\n  input: &quot;Placeholder&quot;\n  input: &quot;Variable_3/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;BiasAdd_3&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;Conv2D_3&quot;\n  input: &quot;conv2d_bias_3/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Relu_3&quot;\n  op: &quot;Relu&quot;\n  input: &quot;BiasAdd_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;MaxPool_3&quot;\n  op: &quot;MaxPool&quot;\n  input: &quot;Relu_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_4/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000@\\000\\000\\000 \\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_4/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_4/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_4/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;truncated_normal_4/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_4/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;truncated_normal_4/TruncatedNormal&quot;\n  input: &quot;truncated_normal_4/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_4&quot;\n  op: &quot;Add&quot;\n  input: &quot;truncated_normal_4/mul&quot;\n  input: &quot;truncated_normal_4/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Variable_4&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 64\n        }\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_4/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_4&quot;\n  input: &quot;truncated_normal_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_4&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_4/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_4&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;zeros_4&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 32\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_4&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 32\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_4/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_4&quot;\n  input: &quot;zeros_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_4&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_4/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_4&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Conv2D_4&quot;\n  op: &quot;Conv2D&quot;\n  input: &quot;MaxPool_3&quot;\n  input: &quot;Variable_4/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;BiasAdd_4&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;Conv2D_4&quot;\n  input: &quot;conv2d_bias_4/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Relu_4&quot;\n  op: &quot;Relu&quot;\n  input: &quot;BiasAdd_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;MaxPool_4&quot;\n  op: &quot;MaxPool&quot;\n  input: &quot;Relu_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_5/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000 \\000\\000\\000\\020\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_5/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_5/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_5/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;truncated_normal_5/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_5/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;truncated_normal_5/TruncatedNormal&quot;\n  input: &quot;truncated_normal_5/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;truncated_normal_5&quot;\n  op: &quot;Add&quot;\n  input: &quot;truncated_normal_5/mul&quot;\n  input: &quot;truncated_normal_5/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;Variable_5&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n        dim {\n          size: 32\n        }\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Variable_5/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;Variable_5&quot;\n  input: &quot;truncated_normal_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_5&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Variable_5/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;Variable_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@Variable_5&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;zeros_5&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 16\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_5&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 16\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_5/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;conv2d_bias_5&quot;\n  input: &quot;zeros_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_5&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;conv2d_bias_5/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;conv2d_bias_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@conv2d_bias_5&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Conv2D_5&quot;\n  op: &quot;Conv2D&quot;\n  input: &quot;MaxPool_4&quot;\n  input: &quot;Variable_5/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;use_cudnn_on_gpu&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;BiasAdd_5&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;Conv2D_5&quot;\n  input: &quot;conv2d_bias_5/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;Relu_5&quot;\n  op: &quot;Relu&quot;\n  input: &quot;BiasAdd_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;MaxPool_5&quot;\n  op: &quot;MaxPool&quot;\n  input: &quot;Relu_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n  attr {\n    key: &quot;ksize&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: &quot;padding&quot;\n    value {\n      s: &quot;SAME&quot;\n    }\n  }\n  attr {\n    key: &quot;strides&quot;\n    value {\n      list {\n        i: 1\n        i: 2\n        i: 2\n        i: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;MaxPool_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Slice/begin&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Slice/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Slice&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Flatten_1/Shape&quot;\n  input: &quot;Flatten_1/Slice/begin&quot;\n  input: &quot;Flatten_1/Slice/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Slice_1/begin&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Slice_1/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 3\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Slice_1&quot;\n  op: &quot;Slice&quot;\n  input: &quot;Flatten_1/Shape&quot;\n  input: &quot;Flatten_1/Slice_1/begin&quot;\n  input: &quot;Flatten_1/Slice_1/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Prod&quot;\n  op: &quot;Prod&quot;\n  input: &quot;Flatten_1/Slice_1&quot;\n  input: &quot;Flatten_1/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/ExpandDims/dim&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/ExpandDims&quot;\n  op: &quot;ExpandDims&quot;\n  input: &quot;Flatten_1/Prod&quot;\n  input: &quot;Flatten_1/ExpandDims/dim&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tdim&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/concat/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/concat&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;Flatten_1/Slice&quot;\n  input: &quot;Flatten_1/ExpandDims&quot;\n  input: &quot;Flatten_1/concat/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;Flatten_1/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;MaxPool_5&quot;\n  input: &quot;Flatten_1/concat&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\000\\001\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_4/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_4/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_4/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_4/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_4/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_4/weights&quot;\n  input: &quot;fully_connected_4/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_4/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_4/biases&quot;\n  input: &quot;fully_connected_4/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_4/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_4/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;Flatten_1/Reshape&quot;\n  input: &quot;fully_connected_4/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_4/MatMul&quot;\n  input: &quot;fully_connected_4/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_4/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;fully_connected_4/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\000\\001\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_5/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_5/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_5/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_5/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_5/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_5/weights&quot;\n  input: &quot;fully_connected_5/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_5/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_5/biases&quot;\n  input: &quot;fully_connected_5/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_5/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_5/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;fully_connected_4/Relu&quot;\n  input: &quot;fully_connected_5/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_5/MatMul&quot;\n  input: &quot;fully_connected_5/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_5/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;fully_connected_5/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\000\\001\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_6/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_6/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_6/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_6/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_6/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_6/weights&quot;\n  input: &quot;fully_connected_6/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_6/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 256\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_6/biases&quot;\n  input: &quot;fully_connected_6/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_6/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_6/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;fully_connected_5/Relu&quot;\n  input: &quot;fully_connected_6/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_6/MatMul&quot;\n  input: &quot;fully_connected_6/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_6/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;fully_connected_6/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;fully_connected_6/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;dropout_1/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;dropout_1/random_uniform/max&quot;\n  input: &quot;dropout_1/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;dropout_1/random_uniform/RandomUniform&quot;\n  input: &quot;dropout_1/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;dropout_1/random_uniform/mul&quot;\n  input: &quot;dropout_1/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;Placeholder_1&quot;\n  input: &quot;dropout_1/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/Floor&quot;\n  op: &quot;Floor&quot;\n  input: &quot;dropout_1/add&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/div&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;fully_connected_6/Relu&quot;\n  input: &quot;Placeholder_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;dropout_1/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;dropout_1/div&quot;\n  input: &quot;dropout_1/Floor&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Initializer/truncated_normal/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\001\\000\\000\\n\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Initializer/truncated_normal/mean&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Initializer/truncated_normal/stddev&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.10000000149011612\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  op: &quot;TruncatedNormal&quot;\n  input: &quot;fully_connected_7/weights/Initializer/truncated_normal/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Initializer/truncated_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;fully_connected_7/weights/Initializer/truncated_normal/TruncatedNormal&quot;\n  input: &quot;fully_connected_7/weights/Initializer/truncated_normal/stddev&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Initializer/truncated_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;fully_connected_7/weights/Initializer/truncated_normal/mul&quot;\n  input: &quot;fully_connected_7/weights/Initializer/truncated_normal/mean&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 256\n        }\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_7/weights&quot;\n  input: &quot;fully_connected_7/weights/Initializer/truncated_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_7/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 10\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 10\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;fully_connected_7/biases&quot;\n  input: &quot;fully_connected_7/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;fully_connected_7/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@fully_connected_7/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;dropout_1/mul&quot;\n  input: &quot;fully_connected_7/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;fully_connected_7/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;fully_connected_7/MatMul&quot;\n  input: &quot;fully_connected_7/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;init&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^Variable/Assign&quot;\n  input: &quot;^conv2d_bias/Assign&quot;\n  input: &quot;^Variable_1/Assign&quot;\n  input: &quot;^conv2d_bias_1/Assign&quot;\n  input: &quot;^Variable_2/Assign&quot;\n  input: &quot;^conv2d_bias_2/Assign&quot;\n  input: &quot;^fully_connected/weights/Assign&quot;\n  input: &quot;^fully_connected/biases/Assign&quot;\n  input: &quot;^fully_connected_1/weights/Assign&quot;\n  input: &quot;^fully_connected_1/biases/Assign&quot;\n  input: &quot;^fully_connected_2/weights/Assign&quot;\n  input: &quot;^fully_connected_2/biases/Assign&quot;\n  input: &quot;^fully_connected_3/weights/Assign&quot;\n  input: &quot;^fully_connected_3/biases/Assign&quot;\n  input: &quot;^beta1_power/Assign&quot;\n  input: &quot;^beta2_power/Assign&quot;\n  input: &quot;^Variable/Adam/Assign&quot;\n  input: &quot;^Variable/Adam_1/Assign&quot;\n  input: &quot;^conv2d_bias/Adam/Assign&quot;\n  input: &quot;^conv2d_bias/Adam_1/Assign&quot;\n  input: &quot;^Variable_1/Adam/Assign&quot;\n  input: &quot;^Variable_1/Adam_1/Assign&quot;\n  input: &quot;^conv2d_bias_1/Adam/Assign&quot;\n  input: &quot;^conv2d_bias_1/Adam_1/Assign&quot;\n  input: &quot;^Variable_2/Adam/Assign&quot;\n  input: &quot;^Variable_2/Adam_1/Assign&quot;\n  input: &quot;^conv2d_bias_2/Adam/Assign&quot;\n  input: &quot;^conv2d_bias_2/Adam_1/Assign&quot;\n  input: &quot;^fully_connected/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected/biases/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_1/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected_1/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_1/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected_1/biases/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_2/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected_2/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_2/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected_2/biases/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_3/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected_3/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_3/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected_3/biases/Adam_1/Assign&quot;\n  input: &quot;^Variable_3/Assign&quot;\n  input: &quot;^conv2d_bias_3/Assign&quot;\n  input: &quot;^Variable_4/Assign&quot;\n  input: &quot;^conv2d_bias_4/Assign&quot;\n  input: &quot;^Variable_5/Assign&quot;\n  input: &quot;^conv2d_bias_5/Assign&quot;\n  input: &quot;^fully_connected_4/weights/Assign&quot;\n  input: &quot;^fully_connected_4/biases/Assign&quot;\n  input: &quot;^fully_connected_5/weights/Assign&quot;\n  input: &quot;^fully_connected_5/biases/Assign&quot;\n  input: &quot;^fully_connected_6/weights/Assign&quot;\n  input: &quot;^fully_connected_6/biases/Assign&quot;\n  input: &quot;^fully_connected_7/weights/Assign&quot;\n  input: &quot;^fully_connected_7/biases/Assign&quot;\n}\nnode {\n  name: &quot;init_1&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^Variable/Assign&quot;\n  input: &quot;^conv2d_bias/Assign&quot;\n  input: &quot;^Variable_1/Assign&quot;\n  input: &quot;^conv2d_bias_1/Assign&quot;\n  input: &quot;^Variable_2/Assign&quot;\n  input: &quot;^conv2d_bias_2/Assign&quot;\n  input: &quot;^fully_connected/weights/Assign&quot;\n  input: &quot;^fully_connected/biases/Assign&quot;\n  input: &quot;^fully_connected_1/weights/Assign&quot;\n  input: &quot;^fully_connected_1/biases/Assign&quot;\n  input: &quot;^fully_connected_2/weights/Assign&quot;\n  input: &quot;^fully_connected_2/biases/Assign&quot;\n  input: &quot;^fully_connected_3/weights/Assign&quot;\n  input: &quot;^fully_connected_3/biases/Assign&quot;\n  input: &quot;^beta1_power/Assign&quot;\n  input: &quot;^beta2_power/Assign&quot;\n  input: &quot;^Variable/Adam/Assign&quot;\n  input: &quot;^Variable/Adam_1/Assign&quot;\n  input: &quot;^conv2d_bias/Adam/Assign&quot;\n  input: &quot;^conv2d_bias/Adam_1/Assign&quot;\n  input: &quot;^Variable_1/Adam/Assign&quot;\n  input: &quot;^Variable_1/Adam_1/Assign&quot;\n  input: &quot;^conv2d_bias_1/Adam/Assign&quot;\n  input: &quot;^conv2d_bias_1/Adam_1/Assign&quot;\n  input: &quot;^Variable_2/Adam/Assign&quot;\n  input: &quot;^Variable_2/Adam_1/Assign&quot;\n  input: &quot;^conv2d_bias_2/Adam/Assign&quot;\n  input: &quot;^conv2d_bias_2/Adam_1/Assign&quot;\n  input: &quot;^fully_connected/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected/biases/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_1/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected_1/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_1/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected_1/biases/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_2/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected_2/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_2/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected_2/biases/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_3/weights/Adam/Assign&quot;\n  input: &quot;^fully_connected_3/weights/Adam_1/Assign&quot;\n  input: &quot;^fully_connected_3/biases/Adam/Assign&quot;\n  input: &quot;^fully_connected_3/biases/Adam_1/Assign&quot;\n  input: &quot;^Variable_3/Assign&quot;\n  input: &quot;^conv2d_bias_3/Assign&quot;\n  input: &quot;^Variable_4/Assign&quot;\n  input: &quot;^conv2d_bias_4/Assign&quot;\n  input: &quot;^Variable_5/Assign&quot;\n  input: &quot;^conv2d_bias_5/Assign&quot;\n  input: &quot;^fully_connected_4/weights/Assign&quot;\n  input: &quot;^fully_connected_4/biases/Assign&quot;\n  input: &quot;^fully_connected_5/weights/Assign&quot;\n  input: &quot;^fully_connected_5/biases/Assign&quot;\n  input: &quot;^fully_connected_6/weights/Assign&quot;\n  input: &quot;^fully_connected_6/biases/Assign&quot;\n  input: &quot;^fully_connected_7/weights/Assign&quot;\n  input: &quot;^fully_connected_7/biases/Assign&quot;\n}\n';
          }
        </script>
        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>
        <div style=&quot;height:600px&quot;>
          <tf-graph-basic id=&quot;graph0.6255653082276177&quot;></tf-graph-basic>
        </div>
    "></iframe>
    
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Train-the-Model">Fully Train the Model<a class="anchor-link" href="#Fully-Train-the-Model">&#182;</a></h3><p>Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Loop over all batches</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
            
    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training...
Epoch  1, CIFAR-10 Batch 1:  Training Loss: 2.1253, Validation Loss: 1.9920, Validation Accuracy: 0.2850
Epoch  1, CIFAR-10 Batch 2:  Training Loss: 1.7484, Validation Loss: 1.7583, Validation Accuracy: 0.3588
Epoch  1, CIFAR-10 Batch 3:  Training Loss: 1.4398, Validation Loss: 1.6234, Validation Accuracy: 0.4012
Epoch  1, CIFAR-10 Batch 4:  Training Loss: 1.4674, Validation Loss: 1.5348, Validation Accuracy: 0.4470
Epoch  1, CIFAR-10 Batch 5:  Training Loss: 1.4472, Validation Loss: 1.4972, Validation Accuracy: 0.4442
Epoch  2, CIFAR-10 Batch 1:  Training Loss: 1.6244, Validation Loss: 1.5134, Validation Accuracy: 0.4636
Epoch  2, CIFAR-10 Batch 2:  Training Loss: 1.3463, Validation Loss: 1.4166, Validation Accuracy: 0.4906
Epoch  2, CIFAR-10 Batch 3:  Training Loss: 1.1124, Validation Loss: 1.4197, Validation Accuracy: 0.4830
Epoch  2, CIFAR-10 Batch 4:  Training Loss: 1.2658, Validation Loss: 1.3822, Validation Accuracy: 0.5006
Epoch  2, CIFAR-10 Batch 5:  Training Loss: 1.1593, Validation Loss: 1.3536, Validation Accuracy: 0.5106
Epoch  3, CIFAR-10 Batch 1:  Training Loss: 1.4233, Validation Loss: 1.3420, Validation Accuracy: 0.5204
Epoch  3, CIFAR-10 Batch 2:  Training Loss: 1.0541, Validation Loss: 1.3092, Validation Accuracy: 0.5200
Epoch  3, CIFAR-10 Batch 3:  Training Loss: 0.9590, Validation Loss: 1.3399, Validation Accuracy: 0.5064
Epoch  3, CIFAR-10 Batch 4:  Training Loss: 1.0632, Validation Loss: 1.2422, Validation Accuracy: 0.5532
Epoch  3, CIFAR-10 Batch 5:  Training Loss: 0.9822, Validation Loss: 1.2348, Validation Accuracy: 0.5516
Epoch  4, CIFAR-10 Batch 1:  Training Loss: 1.1178, Validation Loss: 1.2603, Validation Accuracy: 0.5494
Epoch  4, CIFAR-10 Batch 2:  Training Loss: 0.8322, Validation Loss: 1.2128, Validation Accuracy: 0.5650
Epoch  4, CIFAR-10 Batch 3:  Training Loss: 0.7742, Validation Loss: 1.2033, Validation Accuracy: 0.5676
Epoch  4, CIFAR-10 Batch 4:  Training Loss: 0.8297, Validation Loss: 1.2156, Validation Accuracy: 0.5638
Epoch  4, CIFAR-10 Batch 5:  Training Loss: 0.8279, Validation Loss: 1.1566, Validation Accuracy: 0.5840
Epoch  5, CIFAR-10 Batch 1:  Training Loss: 0.9654, Validation Loss: 1.2001, Validation Accuracy: 0.5750
Epoch  5, CIFAR-10 Batch 2:  Training Loss: 0.7031, Validation Loss: 1.1879, Validation Accuracy: 0.5796
Epoch  5, CIFAR-10 Batch 3:  Training Loss: 0.6133, Validation Loss: 1.1662, Validation Accuracy: 0.5828
Epoch  5, CIFAR-10 Batch 4:  Training Loss: 0.6938, Validation Loss: 1.1280, Validation Accuracy: 0.5944
Epoch  5, CIFAR-10 Batch 5:  Training Loss: 0.6772, Validation Loss: 1.0921, Validation Accuracy: 0.6148
Epoch  6, CIFAR-10 Batch 1:  Training Loss: 0.8163, Validation Loss: 1.1112, Validation Accuracy: 0.6048
Epoch  6, CIFAR-10 Batch 2:  Training Loss: 0.5507, Validation Loss: 1.1085, Validation Accuracy: 0.6016
Epoch  6, CIFAR-10 Batch 3:  Training Loss: 0.4726, Validation Loss: 1.0784, Validation Accuracy: 0.6154
Epoch  6, CIFAR-10 Batch 4:  Training Loss: 0.5501, Validation Loss: 1.1028, Validation Accuracy: 0.6082
Epoch  6, CIFAR-10 Batch 5:  Training Loss: 0.5389, Validation Loss: 1.0392, Validation Accuracy: 0.6312
Epoch  7, CIFAR-10 Batch 1:  Training Loss: 0.7052, Validation Loss: 1.0806, Validation Accuracy: 0.6158
Epoch  7, CIFAR-10 Batch 2:  Training Loss: 0.4776, Validation Loss: 1.0719, Validation Accuracy: 0.6216
Epoch  7, CIFAR-10 Batch 3:  Training Loss: 0.4110, Validation Loss: 1.0541, Validation Accuracy: 0.6284
Epoch  7, CIFAR-10 Batch 4:  Training Loss: 0.4464, Validation Loss: 1.0702, Validation Accuracy: 0.6264
Epoch  7, CIFAR-10 Batch 5:  Training Loss: 0.4518, Validation Loss: 1.0406, Validation Accuracy: 0.6392
Epoch  8, CIFAR-10 Batch 1:  Training Loss: 0.6368, Validation Loss: 1.0270, Validation Accuracy: 0.6388
Epoch  8, CIFAR-10 Batch 2:  Training Loss: 0.3962, Validation Loss: 1.0769, Validation Accuracy: 0.6232
Epoch  8, CIFAR-10 Batch 3:  Training Loss: 0.3493, Validation Loss: 1.0537, Validation Accuracy: 0.6322
Epoch  8, CIFAR-10 Batch 4:  Training Loss: 0.3711, Validation Loss: 1.0364, Validation Accuracy: 0.6340
Epoch  8, CIFAR-10 Batch 5:  Training Loss: 0.4228, Validation Loss: 1.0434, Validation Accuracy: 0.6334
Epoch  9, CIFAR-10 Batch 1:  Training Loss: 0.6008, Validation Loss: 1.0485, Validation Accuracy: 0.6340
Epoch  9, CIFAR-10 Batch 2:  Training Loss: 0.3324, Validation Loss: 1.0095, Validation Accuracy: 0.6474
Epoch  9, CIFAR-10 Batch 3:  Training Loss: 0.2804, Validation Loss: 1.0435, Validation Accuracy: 0.6284
Epoch  9, CIFAR-10 Batch 4:  Training Loss: 0.3506, Validation Loss: 1.0331, Validation Accuracy: 0.6386
Epoch  9, CIFAR-10 Batch 5:  Training Loss: 0.3110, Validation Loss: 1.0158, Validation Accuracy: 0.6534
Epoch 10, CIFAR-10 Batch 1:  Training Loss: 0.4660, Validation Loss: 1.0277, Validation Accuracy: 0.6470
Epoch 10, CIFAR-10 Batch 2:  Training Loss: 0.2963, Validation Loss: 0.9956, Validation Accuracy: 0.6586
Epoch 10, CIFAR-10 Batch 3:  Training Loss: 0.2499, Validation Loss: 1.0277, Validation Accuracy: 0.6384
Epoch 10, CIFAR-10 Batch 4:  Training Loss: 0.2678, Validation Loss: 1.0010, Validation Accuracy: 0.6542
Epoch 10, CIFAR-10 Batch 5:  Training Loss: 0.2399, Validation Loss: 1.0036, Validation Accuracy: 0.6618
Epoch 11, CIFAR-10 Batch 1:  Training Loss: 0.3796, Validation Loss: 0.9919, Validation Accuracy: 0.6680
Epoch 11, CIFAR-10 Batch 2:  Training Loss: 0.2674, Validation Loss: 1.0311, Validation Accuracy: 0.6456
Epoch 11, CIFAR-10 Batch 3:  Training Loss: 0.2329, Validation Loss: 1.0994, Validation Accuracy: 0.6174
Epoch 11, CIFAR-10 Batch 4:  Training Loss: 0.2322, Validation Loss: 1.0475, Validation Accuracy: 0.6492
Epoch 11, CIFAR-10 Batch 5:  Training Loss: 0.1718, Validation Loss: 1.0333, Validation Accuracy: 0.6558
Epoch 12, CIFAR-10 Batch 1:  Training Loss: 0.3730, Validation Loss: 1.0190, Validation Accuracy: 0.6608
Epoch 12, CIFAR-10 Batch 2:  Training Loss: 0.2299, Validation Loss: 0.9717, Validation Accuracy: 0.6642
Epoch 12, CIFAR-10 Batch 3:  Training Loss: 0.2748, Validation Loss: 1.1242, Validation Accuracy: 0.6096
Epoch 12, CIFAR-10 Batch 4:  Training Loss: 0.2046, Validation Loss: 1.0275, Validation Accuracy: 0.6544
Epoch 12, CIFAR-10 Batch 5:  Training Loss: 0.2023, Validation Loss: 1.0104, Validation Accuracy: 0.6558
Epoch 13, CIFAR-10 Batch 1:  Training Loss: 0.3132, Validation Loss: 1.0374, Validation Accuracy: 0.6592
Epoch 13, CIFAR-10 Batch 2:  Training Loss: 0.2230, Validation Loss: 1.0608, Validation Accuracy: 0.6400
Epoch 13, CIFAR-10 Batch 3:  Training Loss: 0.1774, Validation Loss: 1.0071, Validation Accuracy: 0.6522
Epoch 13, CIFAR-10 Batch 4:  Training Loss: 0.1670, Validation Loss: 1.0826, Validation Accuracy: 0.6450
Epoch 13, CIFAR-10 Batch 5:  Training Loss: 0.1786, Validation Loss: 1.0361, Validation Accuracy: 0.6560
Epoch 14, CIFAR-10 Batch 1:  Training Loss: 0.3314, Validation Loss: 1.0817, Validation Accuracy: 0.6552
Epoch 14, CIFAR-10 Batch 2:  Training Loss: 0.1863, Validation Loss: 1.0209, Validation Accuracy: 0.6480
Epoch 14, CIFAR-10 Batch 3:  Training Loss: 0.1506, Validation Loss: 1.0153, Validation Accuracy: 0.6562
Epoch 14, CIFAR-10 Batch 4:  Training Loss: 0.1780, Validation Loss: 1.1913, Validation Accuracy: 0.6336
Epoch 14, CIFAR-10 Batch 5:  Training Loss: 0.1804, Validation Loss: 1.0747, Validation Accuracy: 0.6450
Epoch 15, CIFAR-10 Batch 1:  Training Loss: 0.2522, Validation Loss: 1.0642, Validation Accuracy: 0.6594
Epoch 15, CIFAR-10 Batch 2:  Training Loss: 0.1933, Validation Loss: 1.2041, Validation Accuracy: 0.6150
Epoch 15, CIFAR-10 Batch 3:  Training Loss: 0.1574, Validation Loss: 1.1412, Validation Accuracy: 0.6246
Epoch 15, CIFAR-10 Batch 4:  Training Loss: 0.1146, Validation Loss: 1.1303, Validation Accuracy: 0.6450
Epoch 15, CIFAR-10 Batch 5:  Training Loss: 0.1590, Validation Loss: 1.0357, Validation Accuracy: 0.6688
Epoch 16, CIFAR-10 Batch 1:  Training Loss: 0.1947, Validation Loss: 1.0341, Validation Accuracy: 0.6668
Epoch 16, CIFAR-10 Batch 2:  Training Loss: 0.1559, Validation Loss: 1.0554, Validation Accuracy: 0.6564
Epoch 16, CIFAR-10 Batch 3:  Training Loss: 0.1353, Validation Loss: 1.0883, Validation Accuracy: 0.6436
Epoch 16, CIFAR-10 Batch 4:  Training Loss: 0.0964, Validation Loss: 1.1401, Validation Accuracy: 0.6502
Epoch 16, CIFAR-10 Batch 5:  Training Loss: 0.1105, Validation Loss: 1.0426, Validation Accuracy: 0.6698
Epoch 17, CIFAR-10 Batch 1:  Training Loss: 0.2046, Validation Loss: 1.1037, Validation Accuracy: 0.6586
Epoch 17, CIFAR-10 Batch 2:  Training Loss: 0.1309, Validation Loss: 1.1170, Validation Accuracy: 0.6416
Epoch 17, CIFAR-10 Batch 3:  Training Loss: 0.1534, Validation Loss: 1.3215, Validation Accuracy: 0.5984
Epoch 17, CIFAR-10 Batch 4:  Training Loss: 0.0701, Validation Loss: 1.1197, Validation Accuracy: 0.6560
Epoch 17, CIFAR-10 Batch 5:  Training Loss: 0.0955, Validation Loss: 1.0877, Validation Accuracy: 0.6684
Epoch 18, CIFAR-10 Batch 1:  Training Loss: 0.1903, Validation Loss: 1.2783, Validation Accuracy: 0.6332
Epoch 18, CIFAR-10 Batch 2:  Training Loss: 0.0905, Validation Loss: 1.2281, Validation Accuracy: 0.6296
Epoch 18, CIFAR-10 Batch 3:  Training Loss: 0.1252, Validation Loss: 1.2225, Validation Accuracy: 0.6192
Epoch 18, CIFAR-10 Batch 4:  Training Loss: 0.1124, Validation Loss: 1.1690, Validation Accuracy: 0.6396
Epoch 18, CIFAR-10 Batch 5:  Training Loss: 0.0837, Validation Loss: 1.1143, Validation Accuracy: 0.6622
Epoch 19, CIFAR-10 Batch 1:  Training Loss: 0.2109, Validation Loss: 1.2864, Validation Accuracy: 0.6334
Epoch 19, CIFAR-10 Batch 2:  Training Loss: 0.1079, Validation Loss: 1.2232, Validation Accuracy: 0.6318
Epoch 19, CIFAR-10 Batch 3:  Training Loss: 0.1607, Validation Loss: 1.2303, Validation Accuracy: 0.6248
Epoch 19, CIFAR-10 Batch 4:  Training Loss: 0.0749, Validation Loss: 1.1261, Validation Accuracy: 0.6654
Epoch 19, CIFAR-10 Batch 5:  Training Loss: 0.0849, Validation Loss: 1.1528, Validation Accuracy: 0.6560
Epoch 20, CIFAR-10 Batch 1:  Training Loss: 0.1258, Validation Loss: 1.2519, Validation Accuracy: 0.6438
Epoch 20, CIFAR-10 Batch 2:  Training Loss: 0.1008, Validation Loss: 1.1790, Validation Accuracy: 0.6416
Epoch 20, CIFAR-10 Batch 3:  Training Loss: 0.0959, Validation Loss: 1.2015, Validation Accuracy: 0.6322
Epoch 20, CIFAR-10 Batch 4:  Training Loss: 0.0555, Validation Loss: 1.2301, Validation Accuracy: 0.6462
Epoch 20, CIFAR-10 Batch 5:  Training Loss: 0.0882, Validation Loss: 1.1367, Validation Accuracy: 0.6604
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1><p>The model has been saved to disk.</p>
<h2 id="Test-Model">Test Model<a class="anchor-link" href="#Test-Model">&#182;</a></h2><p>Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Set batch size if not already set</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="k">pass</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">top_n_predictions</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">test_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the saved model against the test dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_test.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
    <span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="c1"># Load model</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_model_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
        <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>

        <span class="c1"># Get Tensors from loaded model</span>
        <span class="n">loaded_x</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;x:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_y</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;y:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;logits:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_acc</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;accuracy:0&#39;</span><span class="p">)</span>
        
        <span class="c1"># Get accuracy in batches for memory limitations</span>
        <span class="n">test_batch_acc_total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">test_batch_count</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">test_feature_batch</span><span class="p">,</span> <span class="n">test_label_batch</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">batch_features_labels</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">test_batch_acc_total</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">loaded_acc</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">test_feature_batch</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">test_label_batch</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">test_batch_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Accuracy: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_batch_acc_total</span><span class="o">/</span><span class="n">test_batch_count</span><span class="p">))</span>

        <span class="c1"># Print Random Samples</span>
        <span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)),</span> <span class="n">n_samples</span><span class="p">)))</span>
        <span class="n">random_test_predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">loaded_logits</span><span class="p">),</span> <span class="n">top_n_predictions</span><span class="p">),</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">random_test_features</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
        <span class="n">helper</span><span class="o">.</span><span class="n">display_image_predictions</span><span class="p">(</span><span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">random_test_predictions</span><span class="p">)</span>


<span class="n">test_model</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from ./image_classification
Testing Accuracy: 0.651953125

</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=355
height=319
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-50-80%-Accuracy?">Why 50-80% Accuracy?<a class="anchor-link" href="#Why-50-80%-Accuracy?">&#182;</a></h2><p>You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130">well above 80%</a>.  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as "dlnd_image_classification.ipynb" and save it as a HTML file under "File" -&gt; "Download as".  Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
